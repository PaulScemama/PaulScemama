<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.340">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>website - Approaches to Curve Fitting</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script>
    MathJax = {
      tex: {
        tags: 'ams'  // should be 'ams', 'none', or 'all'
      }
    };
  </script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">website</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Approaches to Curve Fitting</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#preface" id="toc-preface" class="nav-link active" data-scroll-target="#preface">Preface</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">1 Introduction</a></li>
  <li><a href="#the-deterministic-approach" id="toc-the-deterministic-approach" class="nav-link" data-scroll-target="#the-deterministic-approach">2 The Deterministic Approach</a>
  <ul class="collapse">
  <li><a href="#the-model" id="toc-the-model" class="nav-link" data-scroll-target="#the-model">2.1 The Model</a></li>
  <li><a href="#least-squares-estimation" id="toc-least-squares-estimation" class="nav-link" data-scroll-target="#least-squares-estimation">2.2 Least-Squares Estimation</a></li>
  <li><a href="#overfitting" id="toc-overfitting" class="nav-link" data-scroll-target="#overfitting">2.3 Overfitting</a></li>
  </ul></li>
  <li><a href="#a-probabilistic-approach" id="toc-a-probabilistic-approach" class="nav-link" data-scroll-target="#a-probabilistic-approach">3 A Probabilistic Approach</a>
  <ul class="collapse">
  <li><a href="#the-model-1" id="toc-the-model-1" class="nav-link" data-scroll-target="#the-model-1">3.1 The Model</a></li>
  <li><a href="#maximum-likelihood-estimation" id="toc-maximum-likelihood-estimation" class="nav-link" data-scroll-target="#maximum-likelihood-estimation">3.2 Maximum Likelihood Estimation</a></li>
  <li><a href="#maximum-a-posteriori-estimation" id="toc-maximum-a-posteriori-estimation" class="nav-link" data-scroll-target="#maximum-a-posteriori-estimation">3.3 Maximum a posteriori Estimation</a></li>
  <li><a href="#bayesian-estimation" id="toc-bayesian-estimation" class="nav-link" data-scroll-target="#bayesian-estimation">3.4 Bayesian Estimation</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">4 Summary</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  <li><a href="#appendix" id="toc-appendix" class="nav-link" data-scroll-target="#appendix">Appendix</a>
  <ul class="collapse">
  <li><a href="#solving-for-the-parameters" id="toc-solving-for-the-parameters" class="nav-link" data-scroll-target="#solving-for-the-parameters">1 Solving for the parameters</a></li>
  <li><a href="#solving-for-the-parameters-with-a-penalty-term" id="toc-solving-for-the-parameters-with-a-penalty-term" class="nav-link" data-scroll-target="#solving-for-the-parameters-with-a-penalty-term">2 Solving for the parameters with a penalty term</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="index.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="preface" class="level1">
<h1>Preface</h1>
<p>This post aims to introduce different approaches to curve fitting, and in particular, different <em>parametric</em> approaches to curve fitting. It follows closely section 1.2.5 from Bishop’s <em>Pattern Recognition and Machine Learning</em>, where I expand on some of the more vague concepts introduced. The goal is to see how incorporating particular assumptions into the probabilistic model leads to instances of deterministic approaches. Finally, the Appendix contains some extra derivations and code to “actually do” the curve fitting.</p>
</section>
<section id="introduction" class="level1">
<h1>1 Introduction</h1>
<p>In a canonical scenario, we observe a real-valued variable <span class="math inline">\(t\)</span> and we’d like to <em>model</em> it. Simply put, we’d like to describe a mathematical process describing the creation of <span class="math inline">\(t\)</span>. Once we build such a model we can gather insights and make predictions. In this post, we consider the supervised setting where we model a target variable <span class="math inline">\(t\)</span> as a function of some observed input variable <span class="math inline">\(x\)</span>. To this end, we have gathered a set of <span class="math inline">\(N\)</span> realizations <span class="math inline">\(t_n\)</span> of <span class="math inline">\(t\)</span> together with a corresponding set of realizations <span class="math inline">\(x_n\)</span> of <span class="math inline">\(x\)</span>,</p>
<p><span class="math display">\[
\pmb{\mathsf{x}} = \{x_1, x_2, ..., x_N\}^\intercal, \; \pmb{\mathsf{t}} = \{t_1, t_2, ..., t_N\}^\intercal.
\]</span></p>
<p>In this post, we will consider synthetic data where the underlying data generating process is</p>
<p><span class="math display">\[
t = \text{sin}(2 \pi x) + \mathcal{N}(0, \beta^{-1}), \tag{1.1}
\]</span></p>
<p>where we’ve denoted the variance as <span class="math inline">\(\beta^{-1}\)</span> so that <span class="math inline">\(\beta = 1 / \sigma^2\)</span> which we call the <em>precision</em>. The goal is to exploit our observed data <span class="math inline">\(\{ \pmb{\mathsf{x}}, \pmb{\mathsf{t}} \}\)</span> to create a model of the underlying generative (and random) function <span class="math inline">\((1.1)\)</span> so that we can then do something useful – for example, predict an unobserved value of <span class="math inline">\(t\)</span> for a new observed value of <span class="math inline">\(x\)</span>. The type of modeling discussed in this post is referred to as <em>parametric</em> because, as we shall see, we predefine a family of data-generating functions and then tune the <em>parameters</em> governing those functions according to how well the resultant function explains our observed dataset.</p>
</section>
<section id="the-deterministic-approach" class="level1">
<h1>2 The Deterministic Approach</h1>
<section id="the-model" class="level2">
<h2 class="anchored" data-anchor-id="the-model">2.1 The Model</h2>
<p>In the deterministic approach, we simply consider our target variable <span class="math inline">\(t\)</span> to be a parameterized function of (i) the input variable <span class="math inline">\(x\)</span> and (ii) some unknown parameters <span class="math inline">\(\mathbf{w}\)</span>. In other words, we assume <span class="math inline">\(t\)</span> is the result of a <em>non-random</em> data-generating process which can be described by a function within the family of functions</p>
<p><span class="math display">\[
y(x, \mathbf{w}) = w_0 + w_1x + w_2x^2 + \dots + w_Mx^M = \sum_{j=0}^M w_j x^j, \tag{2.1}
\]</span></p>
<p>where <span class="math inline">\(M\)</span> is the order of the polynomial, and the polynomial coefficients <span class="math inline">\(w_0, ..., w_M\)</span> are packaged in the vector <span class="math inline">\(\mathbf{w}\)</span>. Although <span class="math inline">\(y(x, \mathbf{w})\)</span> is a nonlinear function of <span class="math inline">\(x\)</span>, it is linear in the unknown parameters <span class="math inline">\(\mathbf{w}\)</span>. Functions that are linear in the unknown parameters have special properties and are called <em>linear models</em>.</p>
</section>
<section id="least-squares-estimation" class="level2">
<h2 class="anchored" data-anchor-id="least-squares-estimation">2.2 Least-Squares Estimation</h2>
<p>Although we’re trying to model the variable <span class="math inline">\(t\)</span> as a function of the input variable <span class="math inline">\(x\)</span>, we only have realizations of these variables which we’ve stored in <span class="math inline">\(\{\pmb{\mathsf{x}}, \pmb{\mathsf{t}}\}\)</span>. In the deterministic approach we try and find a setting of <span class="math inline">\(\mathbf{w}\)</span> that best agrees with our dataset <span class="math inline">\(\{\pmb{\mathsf{x}}, \pmb{\mathsf{t}}\}\)</span> by minimizing some notion of “error”. This error measures the misfit between a realized model – the function <span class="math inline">\(y(x, \mathbf{w})\)</span> for a given setting of <span class="math inline">\(\mathbf{w}\)</span> – and the training data points. A widely used (and simple) error function is given by the sum-of-squares of the Euclidean distance between predictions <span class="math inline">\(y(x_n, \mathbf{w})\)</span> and the corresponding target values <span class="math inline">\(t_n\)</span>,</p>
<p><span class="math display">\[
E(\mathbf{w}) = \frac{1}{2} \sum_{n=1}^N \{y(x_n, \mathbf{w}) - t_n \}^2. \tag{2.2}
\]</span></p>
<p>The value of <span class="math inline">\(E(\mathbf{w})\)</span> is always non-negative and is zero only when <span class="math inline">\(y(x, \mathbf{w})\)</span> passes exactly through every training point. Using the error function <span class="math inline">\((2.2)\)</span> in order to find the parameter values for <span class="math inline">\(\mathbf{w}\)</span> is called the method of <em>least-squares</em>. It is visualized in Figure 1.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./img/sum_of_squares.png" class="img-fluid figure-img" width="400"></p>
<figcaption class="figure-caption">Figure 1: The sum-of-squares error function in <span class="math inline">\((3)\)</span> is computed by taking one half the sum of the squared distances of each data point from the function <span class="math inline">\(y(x, \mathbf{w})\)</span>. These displacements are shown in red.</figcaption>
</figure>
</div>
<p>Solving for <span class="math inline">\(\mathbf{w}\)</span> in this setting is fairly straightforward. Because the error function <span class="math inline">\((2.2)\)</span> is a quadratic function of the parameters <span class="math inline">\(\mathbf{w}\)</span>, its derivative with respect to <span class="math inline">\(\mathbf{w}\)</span> will be linear in the elements of <span class="math inline">\(\mathbf{w}\)</span>. Therefore, the minimization of the error function has a unique solution, which we denote <span class="math inline">\(\mathbf{w}^*\)</span>. It can be found in closed form (Appendix <strong>1</strong>). We can then use <span class="math inline">\(y(x, \mathbf{w}^{*})\)</span> to predict new values of the target <span class="math inline">\(t\)</span> for new observed values of the input <span class="math inline">\(x\)</span>.</p>
</section>
<section id="overfitting" class="level2">
<h2 class="anchored" data-anchor-id="overfitting">2.3 Overfitting</h2>
<p>There remains the need to choose the order <span class="math inline">\(M\)</span> of the polynomial, which falls within the realm of <em>model selection</em>. Choosing a large <span class="math inline">\(M\)</span> yields a flexible set of models for us to fit, but they are susceptible to <em>overfitting</em>. We will see later that the least-squares method represents a special case of <em>maximum likelihood</em>, and that overfitting can be viewed as a general symptom of maximum likelihood.</p>
<p>For now, we can continue with a particular method to avoid overfitting – regularization. This involves adding a new term to the error function <span class="math inline">\((2.2)\)</span> that penalizes the parameters <span class="math inline">\(\mathbf{w}\)</span> for being too large. The simplest penalty term to add is the sum-of-squares of the <em>weights</em>. This leads to a new error function,</p>
<p><span class="math display">\[
\overset{\sim}{E} (\mathbf{w}) = \frac{1}{2} \sum_{n=1}^N \{y(x_n, \mathbf{w}) \}^2 + \frac{\lambda}{2} \lVert \mathbf{w} \rVert^2 \tag{2.3},
\]</span></p>
<p>where <span class="math inline">\(\lVert \mathbf{w} \rVert^2 = \mathbf{w}^\intercal \mathbf{w} = w_0^2 + w_1^2 + \dots + w_M^2\)</span> and the parameter <span class="math inline">\(\lambda\)</span> controls the strength of regularization. Like <span class="math inline">\((2.2)\)</span>, the error function <span class="math inline">\((2.3)\)</span> can be minimized in close form (Appendix <strong>2</strong>). Instituting such a penalty term as we did takes on different names depending on the literature. In the statistics literature they are known as shrinkage methods, and in the context of neural networks it is known as weight decay. Lastly, the specific case of <span class="math inline">\((2.3)\)</span> is known as ridge regression.</p>
</section>
</section>
<section id="a-probabilistic-approach" class="level1">
<h1>3 A Probabilistic Approach</h1>
<section id="the-model-1" class="level2">
<h2 class="anchored" data-anchor-id="the-model-1">3.1 The Model</h2>
<p>In the deterministic approach we assumed <span class="math inline">\(t\)</span> to be the result of a deterministic function of <span class="math inline">\(x\)</span> and unknown parameters <span class="math inline">\(\mathbf{w}\)</span>. We now consider a <em>probabilistic</em> model so that we can express uncertainty in our predictions.</p>
<p>We may not want to make such a strong statement as saying “<span class="math inline">\(t\)</span> is exactly equal to <span class="math inline">\(y(x, \mathbf{w})\)</span>” as we did in the previous section. This could be because we think there is noise in the observations <span class="math inline">\(\pmb{\mathsf{t}}\)</span>, for example due to measurement error. To articulate this assumed reality we need to place a distribution over the target variable <span class="math inline">\(t\)</span>. A sensible distributional assumption is to place a Gaussian distribution over <span class="math inline">\(t\)</span> with its mean given by the parameterized function <span class="math inline">\(y(x, \mathbf{w})\)</span> and its variance being fixed and unknown. This is visualized in Figure 2.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./img/gaussian_noise_model.png" class="img-fluid figure-img" width="400"></p>
<figcaption class="figure-caption">Figure 2: Illustration of a Gaussian conditional distribution over <span class="math inline">\(t\)</span> conditioned on <span class="math inline">\(x\)</span> where the mean of the distribution is given by some function of <span class="math inline">\(x\)</span>, and the variance is fixed</figcaption>
</figure>
</div>
<p>To understand what we’re effectively saying when we create such a model, it is useful to re-emphasize and apply the <em>data-generating process</em> perspective. We can think of our model as describing a process that produces <span class="math inline">\(t\)</span> from a given <span class="math inline">\(x\)</span> and parameter setting <span class="math inline">\(\mathbf{w}\)</span>. Last section, this process was a deterministic function <span class="math inline">\(y(x, \mathbf{w})\)</span>. In this section, we extend the process by positing that each <span class="math inline">\(t\)</span> is the result of <span class="math inline">\(y(x, \mathbf{w})\)</span> <em>and some additive uncertainty</em>, where that additive uncertainty takes the form of a zero-mean Gaussian distribution with unknown variance. This is to say that we are assuming, to have gotten a particular instance of <span class="math inline">\(t\)</span>:</p>
<ul>
<li>we are given an instance of <span class="math inline">\(x\)</span>,</li>
<li>this instance of <span class="math inline">\(x\)</span> is then used to obtain the output of the parameterized function <span class="math inline">\(y(x, \mathbf{w})\)</span>,</li>
<li>to which we add a sample from a zero-mean Gaussian with fixed and unknown variance.</li>
</ul>
<p>This leads to the following model,</p>
<p><span class="math display">\[\begin{align}
p(t|x, \mathbf{w}, \beta) &amp;= y(x, \mathbf{w}) + \mathcal{N}(0, \beta^{-1}) \notag \\
&amp;= \mathcal{N}(y(x, \mathbf{w}), \beta^{-1}), \tag{3.1}
\end{align}\]</span></p>
<p>where we’ve used the scaling property of the Gaussian distribution’s mean. <span class="math inline">\((3.1)\)</span> is an <em>observation model</em> and is more specifically referred to as the <em>Gaussian noise</em> model or a <em>conditional Gaussian</em> model.</p>
</section>
<section id="maximum-likelihood-estimation" class="level2">
<h2 class="anchored" data-anchor-id="maximum-likelihood-estimation">3.2 Maximum Likelihood Estimation</h2>
<p>In order to use the training dataset <span class="math inline">\(\{\pmb{\mathsf{x}}, \pmb{\mathsf{t}}\}\)</span> to determine the values of the unknown parameters <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(\beta\)</span>, we will use a more general approach than error minimization – <em>maximum likelihood estimation</em>. As the name suggests, we will search for a setting of <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(\beta\)</span> so that the likelihood of our observed data <span class="math inline">\(\pmb{\mathsf{t}}\)</span> is maximized. In other words, we’ve defined a data-generating process, and we want to find the setting of the parameters such that the probabilities of our process having <em>created</em> each observed <span class="math inline">\(t_n \in \pmb{\mathsf{t}}\)</span> from each <span class="math inline">\(x_n \in \pmb{\mathsf{x}}\)</span> are maximized. The likelihood measures the aggregation of all these point-wise probabilities.</p>
<p>In order to use maximum likelihood estimation, we need to have a <em>likelihood function</em>. A likelihood function is <em>derived</em> from an observation model. It can be thought of as an observation model being <em>applied</em> to a particular dataset. Assuming the data <span class="math inline">\(\pmb{\mathsf{t}}\)</span> were independently sampled from <span class="math inline">\((3.1)\)</span>, the likelihood function is the product of evaluating how consistent the model is with each datapoint <span class="math inline">\((t_n, x_n)\)</span>, and is evaluated for a particular setting of <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(\beta\)</span>,</p>
<p><span class="math display">\[
p(\pmb{\mathsf{t}}| \pmb{\mathsf{x}}, \mathbf{w}, \beta) = \prod_{n=1}^N \mathcal{N}(t_n|y(x_n, \mathbf{w}), \beta^{-1}). \tag{3.2}
\]</span></p>
<p>Each time we choose a setting for <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(\beta\)</span> and plug them into our model, we are defining a conditional distribution given by <span class="math inline">\((3.1)\)</span>. This conditional distribution may agree with the dataset we have, or it may not. Examples of agreement and disagreement are shown in Figure 3.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./img/gaussian_noise_model_disagreement.png" class="img-fluid figure-img" width="500"></p>
<figcaption class="figure-caption">Figure 3: A Gaussian noise model shown for a handful of <span class="math inline">\(x_i\)</span>, with two different settings for <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(\beta\)</span>. On the left is a setting of <span class="math inline">\((\mathbf{w}, \beta)\)</span> that induces a model that disagrees with our observed data. On the right is a setting of <span class="math inline">\((\mathbf{w}, \beta)\)</span> that induces a model that agrees much better with our observed data. Maximum likelihood looks for a setting of <span class="math inline">\((\mathbf{w}, beta)\)</span> that best agrees with our observed data.</figcaption>
</figure>
</div>
<p>We now demonstrate how, in practice, we compute the maximum likelihood estimates for <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(\beta\)</span>. In this example, it can be done in closed form and amounts to taking the derivative of the likelihood <span class="math inline">\((3.2)\)</span>, setting it equal to zero, and then solving for <span class="math inline">\(\mathbf{w}\)</span> or <span class="math inline">\(\beta\)</span>. We begin with <span class="math inline">\(\mathbf{w}\)</span>. It is common to instead maximize the log likelihood instead of the likelihood <span class="math inline">\((3.2)\)</span> for numerical stability and convenience. We can write the log likelihood as</p>
<p><span class="math display">\[
\text{ln}p(\pmb{\mathsf{t}}| \pmb{\mathsf{x}}, \mathbf{w}, \beta) = - \frac{\beta}{2} \sum_{n=1}^N \{y(x_n ,\mathbf{w}) - t_n \}^2 + \frac{N}{2} \text{ln}\beta - \frac{N}{2} \text{ln}(2 \pi). \tag{3.3}
\]</span></p>
<section id="maximum-likelihoods-connection-to-least-squares" class="level4">
<h4 class="anchored" data-anchor-id="maximum-likelihoods-connection-to-least-squares"><strong>3.2.1 Maximum Likelihood’s connection to Least-Squares</strong></h4>
<p>In taking the derivative of <span class="math inline">\((3.3)\)</span> with respect to <span class="math inline">\(\mathbf{w}\)</span>, we can omit the last two terms as they do not depend on <span class="math inline">\(\mathbf{w}\)</span>. We can also replace the coefficient <span class="math inline">\(\frac{\beta}{2}\)</span> with <span class="math inline">\(\frac{1}{2}\)</span> since scaling <span class="math inline">\((3.3)\)</span> by a constant won’t change the location of the maximum of <span class="math inline">\((3.3)\)</span> with respect to <span class="math inline">\(\mathbf{w}\)</span>. Lastly, we can equivalently minimize the <em>negative</em> log likelihood. This leaves us with minimizing</p>
<p><span class="math display">\[
\frac{1}{2} \sum_{n=1}^N \{y(x_n, \mathbf{w}) - t_n \}^2. \tag{3.4}
\]</span></p>
<p>And so we see that the sum-of-squares error function has arisen as a consequence of maximizing the likelihood under the assumption of a Gaussian noise distribution. In fact, for a <em>Gaussian noise model</em>, maximum likelihood estimation and least-squares estimation find the same <span class="math inline">\(\mathbf{w}\)</span>; in particular, the one that minimizes <span class="math inline">\((3.4)\)</span>. Once we’ve found the maximum likelihood estimate for <span class="math inline">\(\mathbf{w}\)</span>, which we will denote <span class="math inline">\(\mathbf{w}_{\text{ML}}\)</span>, we can use it to find the setting for the precision parameter <span class="math inline">\(\beta\)</span> of the Gaussian conditional distribution. Maximizing <span class="math inline">\((3.3)\)</span> with respect to <span class="math inline">\(\beta\)</span> yields</p>
<p><span class="math display">\[
\frac{1}{\beta_{\text{ML}}} = \frac{1}{N} \sum_{n=1}^N \{y(x_n, \mathbf{w}_{\text{ML}}) - t_n \}^2. \tag{3.5}
\]</span></p>
<p>And so we see that the maximum likelihood procedure yields a variance <span class="math inline">\(\sigma^2\)</span> as equalling the average squared deviation between the observed data points and the function <span class="math inline">\(y(x, \mathbf{w}_{\text{ML}})\)</span>.</p>
</section>
<section id="maximum-likelihoods-predictive-distribution" class="level4">
<h4 class="anchored" data-anchor-id="maximum-likelihoods-predictive-distribution"><strong>3.2.2 Maximum Likelihood’s predictive distribution</strong></h4>
<p>The predictive distribution as a result of the maximum likelihood approach amounts to plugging in the maximum likelihood estimates <span class="math inline">\(\mathbf{w}_{\text{ML}}\)</span> and <span class="math inline">\(\beta_{\text{ML}}\)</span> into the observation model 3.1:</p>
<p><span class="math display">\[
p(t|x, \mathbf{w}_{\text{ML}}, \beta_{\text{ML}}) = \mathcal{N}(y(x, \mathbf{w}_{\text{ML}}), \beta^{-1}_{\text{ML}}). \tag{3.6}
\]</span></p>
</section>
</section>
<section id="maximum-a-posteriori-estimation" class="level2">
<h2 class="anchored" data-anchor-id="maximum-a-posteriori-estimation">3.3 Maximum a posteriori Estimation</h2>
<p>Introducing a prior distribution over the parameters <span class="math inline">\(\mathbf{w}\)</span> is a way of introducing our <em>prior</em> beliefs (perhaps through domain expertise) about the parameters before observing our dataset. Additionally, as we will see, it serves as a <em>regularizer</em> for our estimate of <span class="math inline">\(\mathbf{w}\)</span>. Importantly, it is also one of the components in Bayes’ theorem, and takes us a step towards a full Bayesian treatment. For simplicity, we introduce a simple Gaussian prior</p>
<p><span class="math display">\[
p(\mathbf{w}| \alpha) = \mathcal{N}(\mathbf{w} | \mathbf{0}, \alpha^{-1} \mathbf{I}) = \left( \frac{\alpha}{2 \pi} \right)^{(M+1) / 2} \text{exp} \left[- \frac{\alpha}{2} \mathbf{w}^{\intercal} \mathbf{w} \right], \tag{3.7}
\]</span></p>
<p>where <span class="math inline">\(\alpha\)</span> is the precision of the distribution and <span class="math inline">\(M+1\)</span> is the number of elements in <span class="math inline">\(\mathbf{w}\)</span> for an <span class="math inline">\(M\)</span> order polynomial function. Variables such as <span class="math inline">\(\alpha\)</span> are called <em>hyperparameters</em> since we have to choose their values. Now that we have a prior, we can use Bayes’ theorem to yield a quantity proportional to the posterior,</p>
<p><span class="math display">\[
\overbrace{ p(\mathbf{w}|\pmb{\mathsf{x}}, \pmb{\mathsf{t}}, \alpha, \beta) }^{\text{Posterior } p(\mathbf{w}|D)} = \frac{\overbrace{p(\pmb{\mathsf{t}}|\pmb{\mathsf{x}}, \mathbf{w}, \beta)}^{\text{Likelihood } p(D|\mathbf{w})} \; \cdot \; \overbrace{p(\mathbf{w}|\alpha)}^{\text{Prior }p(\mathbf{w})}}{\underbrace{p(\pmb{\mathsf{t}}|\pmb{\mathsf{x}})}_{\text{Model Evidence } p(D)}} \propto \overbrace{p(\pmb{\mathsf{t}}|\pmb{\mathsf{x}}, \mathbf{w}, \beta)}^{\text{Likelihood } p(D|\mathbf{w})} \; \cdot \; \overbrace{p(\mathbf{w}|\alpha)}^{\text{Prior }p(\mathbf{w})}, \tag{3.8}
\]</span></p>
<p>where the proportion relation <span class="math inline">\(\propto\)</span> comes from the fact that the denominator of Bayes’ theorem, <span class="math inline">\(p(D) = p(\mathbf{t} | \mathbf{x})\)</span>, does not depend on <span class="math inline">\(\mathbf{w}\)</span>. Maximizing the right hand size of <span class="math inline">\((3.8)\)</span> with respect to <span class="math inline">\(\mathbf{w}\)</span> is equivalent to maximizing the posterior with respect to <span class="math inline">\(\mathbf{w}\)</span> due to the proportionality. By optimizing <span class="math inline">\(\mathbf{w}\)</span> to maximize the posterior, we are finding the most probable parameter values <span class="math inline">\(\mathbf{w}\)</span> considering our observed data and also our prior knowledge about <span class="math inline">\(\mathbf{w}\)</span> encapsulated in the (data independent) prior <span class="math inline">\(p(\mathbf{w} | \alpha)\)</span>. This yields a tradeoff between what we believed about <span class="math inline">\(\mathbf{w}\)</span> before seeing our data, and the <span class="math inline">\(\mathbf{w}\)</span> that best fits our data. This technique is referred to <em>maximum a posteriori estimation</em>, MAPE, or MAP.</p>
<section id="maximum-a-posterioris-connection-to-least-squares" class="level4">
<h4 class="anchored" data-anchor-id="maximum-a-posterioris-connection-to-least-squares"><strong>3.3.1 Maximum a posteriori’s connection to Least-Squares</strong></h4>
<p>Taking the negative logarithm of <span class="math inline">\((3.8)\)</span> and combining with the log likelihood in <span class="math inline">\((3.3)\)</span> and the prior in <span class="math inline">\((3.7)\)</span>, it can be shown that the maximum of the posterior is equivalenty the minimum of the following expression:</p>
<p><span class="math display">\[
\frac{\beta}{2} \sum_{n=1}^N \{y(x_n, \mathbf{w}) - t_n \}^2 + \frac{\alpha}{2} \mathbf{w}^\intercal \mathbf{w}. \tag{3.9}
\]</span></p>
<p>If we define <span class="math inline">\(\lambda = \alpha / \beta\)</span>, we can rewrite <span class="math inline">\((3.9)\)</span> as</p>
<p><span class="math display">\[
\frac{1}{2} \sum_{n=1}^N \{y(x_n, \mathbf{w}) - t_n \}^2 + \frac{\lambda}{2} \mathbf{w}^\intercal \mathbf{w}. \tag{3.10}
\]</span></p>
<p>And so we see that minimizing the regularized sum-of-squares function introduced in <span class="math inline">\((4)\)</span> arises naturally from maximizing the posterior of a Gaussian noise model with Gaussian prior.</p>
<p>Similar to the maximum likelihood section, once we’ve found the maximum a posteriori estimate for <span class="math inline">\(\mathbf{w}\)</span>, which we will denote <span class="math inline">\(\mathbf{w}_{\text{MAP}}\)</span>, we can use it to find the setting for the precision parameter <span class="math inline">\(\beta\)</span>. We did not introduce a prior over <span class="math inline">\(\beta\)</span>, so the negative logarithm of the right-hand-side of <span class="math inline">\((3.8)\)</span> is</p>
<p><span class="math display">\[
-\text{ln} \left[ \: p(\pmb{\mathsf{t}}|\pmb{\mathsf{x}}, \mathbf{w}, \beta) p(\mathbf{w}|\alpha)  \: \right] = -[ \: \text{ln}p(\pmb{\mathsf{t}}|\pmb{\mathsf{x}}, \mathbf{w}, \beta) + \text{ln} p(\mathbf{w}|\alpha) \: ]. \tag{3.11}
\]</span></p>
<p>Since we’ve only gained an additive term that does not functionally depend on <span class="math inline">\(\beta\)</span>, solving for <span class="math inline">\(\beta_{\text{MAP}}\)</span> yields a near-equivalent expression to <span class="math inline">\((3.5)\)</span> except we now use <span class="math inline">\(\mathbf{w}_{\text{MAP}}\)</span> instead of <span class="math inline">\(\mathbf{w}_{\text{ML}}\)</span>:</p>
<p><span class="math display">\[
\frac{1}{\beta_{\text{MAP}}} = \frac{1}{N} \sum_{n=1}^{N} \{y(x_n, \mathbf{w}_{\text{MAP}}) - t_n\}^2. \tag{3.12}
\]</span></p>
</section>
<section id="maximum-a-posterioris-predictive-distribution" class="level4">
<h4 class="anchored" data-anchor-id="maximum-a-posterioris-predictive-distribution"><strong>3.3.2 Maximum a posteriori’s predictive distribution</strong></h4>
<p>Similar to Maximum Likelihood, the result of the <em>maximum a posteriori estimation</em> method are point-estimates for the parameters <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(\beta\)</span>. We can similarly plug in those estimates, denoted <span class="math inline">\(\mathbf{w}_{\text{MAP}}\)</span> and <span class="math inline">\(\beta_{\text{MAP}}\)</span>, into the observation model <span class="math inline">\((3.1)\)</span>:</p>
<p><span class="math display">\[
p(t|x, \mathbf{w}_{\text{MAP}}, \beta_{\text{MAP}}) = \mathcal{N}(y(x, \mathbf{w}_{\text{MAP}}), \beta^{-1}_{\text{MAP}}). \tag{3.13}
\]</span></p>
</section>
</section>
<section id="bayesian-estimation" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-estimation">3.4 Bayesian Estimation</h2>
<p>So far we have been making a point estimate of <span class="math inline">\(\mathbf{w}\)</span> which does not yet amount to a Bayesin treatment. In a Bayesian treatment, we take into account all possible <span class="math inline">\(\mathbf{w}\)</span> that could have explained our data. To predict a new value of <span class="math inline">\(t\)</span> for a new <span class="math inline">\(x\)</span>, we marginalize over all possible settings of <span class="math inline">\(\mathbf{w}\)</span>, yielding the <em>posterior predictive distribution</em> or <em>Bayesian model average</em>. The goal of the Bayesian treatment is to compute the posterior over the weights <span class="math inline">\(p(\mathbf{w}|D)\)</span> which represents all possible settings of <span class="math inline">\(\mathbf{w}\)</span> that give rise to models that can explain our observed data <span class="math inline">\(D\)</span>. To this end, we must use Bayes’ theorem:</p>
<p><span class="math display">\[
p(\mathbf{w}|D) = \frac{p(D|\mathbf{w})p(\mathbf{w})}{p(D)}. \tag{3.14}
\]</span></p>
<p>And for our regression problem in particular, <span class="math inline">\((3.14)\)</span> can be further specified as</p>
<p><span class="math display">\[
p(\mathbf{w}|\pmb{\mathsf{t}}, \pmb{\mathsf{x}}, \alpha, \beta) = \frac{\overbrace{p(\pmb{\mathsf{t}} | \pmb{\mathsf{x}}, \mathbf{w}, \beta)}^{\text{Likelihood}} \cdot \overbrace{p(\mathbf{w} | \alpha)}^{\text{Prior}}}{\underbrace{p(\pmb{\mathsf{t}} | \pmb{\mathsf{x}})}_{\text{Evidence}}}.
\tag{3.15}
\]</span></p>
<p>To simplify this, we will assume the parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are fixed and known in advance, and we will solely focus on the unknown <span class="math inline">\(\mathbf{w}\)</span>. <span class="math inline">\((3.15)\)</span> then turns into</p>
<p><span class="math display">\[
p(\mathbf{w} \vert \pmb{\mathsf{x}}, \pmb{\mathsf{t}}) = \frac{p(\pmb{\mathsf{t}} \vert \pmb{\mathsf{x}}, \mathbf{w}) \cdot p(\mathbf{w})}{p(\pmb{\mathsf{t}} \vert \pmb{\mathsf{x}})}. \tag{3.16}
\]</span></p>
<p>So instead of computing a single <em>point estimate</em> of the weights (as we’ve done thus far); now, given the likelihood and the prior, we can compute the <em>posterior distribution</em> over <span class="math inline">\(\mathbf{w}\)</span> via Bayes’ rule. Computing the posterior can be facilitated by our choice of prior (a modeling choice) so that we can calculate the posterior in closed form. Those priors are referred to as <em>conjugate priors</em>. There are a number of other techniques used to instead <em>approximate</em> the posterior <span class="math inline">\(p(\mathbf{w}|\pmb{\mathsf{t}}, \pmb{\mathsf{x}})\)</span> when conjugacy is impossible. These include <em>variational inference</em> and <em>markov chain monte carlo sampling</em>. Pretty much all posterior approximation methods introduce different ways to circumvent the explicit calculation of the denominator <span class="math inline">\(P(D) = p(\pmb{\mathsf{t}}|\pmb{\mathsf{x}})\)</span> which is intractable for any interesting model. We save all these methods for another post and assume we’ve found the exact posterior.</p>
<section id="bayesians-predictive-distribution" class="level4">
<h4 class="anchored" data-anchor-id="bayesians-predictive-distribution"><strong>3.4.1 Bayesian’s predictive distribution</strong></h4>
<p>Once it is found, the posterior represents all possible settings of <span class="math inline">\(\mathbf{w}\)</span> in that they induce models that can explain our data. To incorporate this information into a <em>predictive distribution</em> so that we can predict new values of an unobserved <span class="math inline">\(t\)</span> given an unobserved <span class="math inline">\(x\)</span>, we marginalize over all possible settings of <span class="math inline">\(\mathbf{w}\)</span> like so:</p>
<p><span class="math display">\[
p(t|x, \pmb{\mathsf{x}}, \pmb{\mathsf{t}}) = \int p(t|x, \mathbf{w}) p(\mathbf{w}|\pmb{\mathsf{x}}, \pmb{\mathsf{t}}) \text{d}\mathbf{w}, \tag{3.17}
\]</span></p>
<p>where <span class="math inline">\(p(t|x, \mathbf{w})\)</span> is our model given by <span class="math inline">\((3.1)\)</span> omitting the dependence on <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(p(\mathbf{w}|\pmb{\mathsf{x}}, \pmb{\mathsf{t}})\)</span> is the posterior over the weights <span class="math inline">\(\mathbf{w}\)</span>. In <span class="math inline">\((3.15)\)</span>,</p>
<ul>
<li>we look at a possible setting of <span class="math inline">\(\mathbf{w}\)</span> which we will denote <span class="math inline">\(\mathbf{w}_i\)</span> according to the posterior <span class="math inline">\(p(\mathbf{w}|\pmb{\mathsf{x}}, \pmb{\mathsf{t}})\)</span>. Placing <span class="math inline">\(\mathbf{w}_i\)</span> into our observation model <span class="math inline">\(p(t|x, \mathbf{w})\)</span> defines a “fitted model” <span class="math inline">\(p(t|x, \mathbf{w}_i)\)</span>.</li>
<li>this “fitted model” is <em>multiplied</em> by the probability of that setting of <span class="math inline">\(\mathbf{w}_i\)</span> given by the posterior. In other words, the probability that <span class="math inline">\(p(t|x, \mathbf{w}_i)\)</span> was used to generate our observed data <span class="math inline">\(\pmb{\mathsf{t}}\)</span> from the inputs <span class="math inline">\(\pmb{\mathsf{x}}\)</span>.</li>
<li>we do this for every possible setting <span class="math inline">\(\mathbf{w}_i\)</span> according to the posterior and integrate.</li>
</ul>
<p>Thus, we are taking a weighted average of all possible “fitted models”, where the weights of each component are determined by how likely the setting of <span class="math inline">\(\mathbf{w}\)</span> is according to its posterior.</p>
</section>
<section id="analyzing-our-specific-predictive-distribution" class="level4">
<h4 class="anchored" data-anchor-id="analyzing-our-specific-predictive-distribution"><strong>3.4.2 Analyzing our specific predictive distribution</strong></h4>
<p>We will now analyze the specific form of <span class="math inline">\((3.17)\)</span> for our example problem. A consequence of us selecting a Gaussian likelihood and a Gaussian prior is that we can analytically compute the posterior; and it is Gaussian as well – an example of <em>conjugacy</em>. More so, we can analytically solve the integration in <span class="math inline">\((3.17)\)</span> to get a predictive distribution that itself is Gaussian. In fact, it takes on the more specific form</p>
<p><span class="math display">\[
p(t|x, \pmb{\mathsf{x}}, \pmb{\mathsf{t}}) = \mathcal{N}(t|m(x), s^2(x)), \tag{3.18}
\]</span></p>
<p>where the mean and variance are given by</p>
<p><span class="math display">\[\begin{align}
&amp;m(x) = \beta \pmb{\phi}(x)^{\intercal} \mathbf{S} \sum_{n=1}^N \pmb{\phi}(x_n) t_n \tag{3.19} \\
&amp; s^2(x) = \overbrace{\beta^{-1}}^{\text{noise}} + \underbrace{\pmb{\phi}(x)^\intercal \mathbf{S} \pmb{\phi}(x)}_{\text{Parameter Uncertainty}} \tag{3.20}
\end{align}\]</span></p>
<p><span class="math inline">\(\mathbf{S}\)</span> is a matrix, and is given by</p>
<p><span class="math display">\[
\mathbf{S}^{-1} = \alpha \mathbf{I} + \beta \sum_{n=1}^N \pmb{\phi}(x_n)  \pmb{\phi}(x),^\intercal \tag{3.21}
\]</span></p>
<p>where <span class="math inline">\(\mathbf{I}\)</span> is the unit matrix, and we have defined the vector <span class="math inline">\(\pmb{\phi}(x)\)</span> with elements <span class="math inline">\(\phi_i(x) = x^i\)</span> for <span class="math inline">\(i=0,...,M\)</span>. In looking at the predictive distribution <span class="math inline">\((3.16)\)</span>, we now see that the variance depends on <span class="math inline">\(x\)</span>. This is <em>unlike</em> the maximum likelihood predictive distribution <span class="math inline">\((3.6)\)</span> and the maximum a posteriori predictive distribution <span class="math inline">\((3.13)\)</span> where the variance is fixed for any value of <span class="math inline">\(x\)</span>. It’s expansion is described by <span class="math inline">\((3.20)\)</span> and it contains two additive components. The first component, as was already expressed in the maximum likelihood predictive distribution <span class="math inline">\(\beta_{\text{ML}}\)</span>, is the noise on the target variables. The second component, which <em>has not</em> been expressed until now, arises from the <em>uncertainty in the parameters</em> <span class="math inline">\(\mathbf{w}\)</span> and is a consequence of treating <span class="math inline">\(\mathbf{w}\)</span> as a random variable – an artifact of the Bayesian treatment.</p>
</section>
</section>
</section>
<section id="summary" class="level1">
<h1>4 Summary</h1>
<ul>
<li><p>If we assume a Gaussian noise observation model and use maximum likelihood to find the setting for the parameters <span class="math inline">\(\mathbf{w}\)</span>, it is equivalent to using least-squares to find <span class="math inline">\(\mathbf{w}\)</span>.</p></li>
<li><p>If we assume a Gaussian noise observation model and an Isotropic Gaussian prior model on <span class="math inline">\(\mathbf{w}\)</span>, and then use maximum a posteriori to find the setting for <span class="math inline">\(\mathbf{w}\)</span>, it is equivalent to using least-squares with weight decay regularization to find <span class="math inline">\(\mathbf{w}\)</span>.</p></li>
<li><p>If we assume a Gaussian noise observation model and an Isotropic Gaussian prior model on <span class="math inline">\(\mathbf{w}\)</span>, and then we use the Bayesian approach, we do not find a setting for <span class="math inline">\(\mathbf{w}\)</span>, but rather a distribution over <span class="math inline">\(\mathbf{w}\)</span>. This allows us to introduce parameter uncertainty in our predictive distribution – a result of many different settings of <span class="math inline">\(\mathbf{w}\)</span> that could explain the training data.</p></li>
</ul>
</section>
<section id="references" class="level1">
<h1>References</h1>
<p><a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf"><em>Pattern Recognition and Machine Learning</em></a>, <strong>Christopher M. Bishop</strong>, 2006</p>
<p><a href="https://www.miketipping.com/papers/met-mlbayes.pdf"><em>Bayesian Inference: An Introduction to Principles and Practice in Machine Learning</em></a> <strong>Michael E. Tipping</strong>, 2004</p>
</section>
<section id="appendix" class="level1">
<h1>Appendix</h1>
<section id="solving-for-the-parameters" class="level2">
<h2 class="anchored" data-anchor-id="solving-for-the-parameters">1 Solving for the parameters</h2>
<section id="analytical-setup" class="level4">
<h4 class="anchored" data-anchor-id="analytical-setup"><strong>1.1 Analytical Setup</strong></h4>
<p>We have the error function <span class="math inline">\(E(\mathbf{w}) = \frac{1}{2} \sum_{n=1}^N \{y(x_n, \mathbf{w}) - t_n \}^2\)</span>, where <span class="math inline">\(y(x, \mathbf{w}) = \sum_{j=0}^M w_j x^j\)</span>. We’d like to find the optimal setting for <span class="math inline">\(\mathbf{w}\)</span> in the sense that it minimizes <span class="math inline">\(E(\mathbf{w})\)</span>. We will see that we can cast this minimization problem as solving a system of linear equations. We will then solve that system of linear equations with code to attain the optimal <span class="math inline">\(\mathbf{w}^{*}\)</span>.</p>
<p><em>Claim</em>: The <span class="math inline">\(w_i\)</span> in <span class="math inline">\(\mathbf{w} = (w_0, w_1, w_2 ..., w_M)\)</span> that minimize the error function <span class="math inline">\(E(\mathbf{w})\)</span> are given by the solution to the following set of linear equations,</p>
<p><span class="math display">\[
\sum_{j=0}^M A_{ij}w_j = T_i \;\; \text{ where } \;\; A_{ij} = \sum_{n=1}^N(x_n)^{(i+j)}, \; T_i = \sum_{n=1}^N (x_n)^i t_n
\]</span></p>
<p><em>Proof</em>: We will take the derivative of <span class="math inline">\(E(\mathbf{w})\)</span> with respect to <span class="math inline">\(\mathbf{w}\)</span>, set it to zero, and then rearrange terms to prove the claim above.</p>
<p>By the chain rule,</p>
<p><span class="math display">\[
\frac{\partial E(\mathbf{w})}{\partial w_i} = \frac{\partial E(\mathbf{w})}{\partial y(x_n, \mathbf{w})} \frac{\partial y(x_n, \mathbf{w})}{\partial w_i} \tag{1}
\]</span></p>
<p>Solving the two terms on the right hand side yields</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\frac{\partial E(\mathbf{w})}{\partial y(x_n, \mathbf{w})} = \sum_{n=1}^N \{y(x_n, \mathbf{w}) - t_n \} \\
&amp;\frac{\partial y(x_n, \mathbf{w})}{\partial w_i} = \frac{\partial}{\partial w_i} (w_0 + w_1x_1 + \dots w_i x_n^i \dots + w_m x_n^M) = x_n^i
\end{aligned}
\]</span></p>
<p>Substituting back into <span class="math inline">\((1)\)</span> yields</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial E(\mathbf{w})}{\partial w_i} &amp; = \sum_{n=1}^N \{y(x_n, \mathbf{w}) - t_n \} x_n^i \\
&amp; \overset{(i)}{=} \sum_{n=1}^N (\sum_{j=0}^M w_j x_n^{j} - t_n)x_n^i \\
&amp; \overset{(ii)}{=} \sum_{n=1}^N (\sum_{j=0}^M w_j x_n^{i}x_n^j - t_n x_n^i) \\
&amp; \overset{(iii)}{=} \sum_{n=1}^N (\sum_{j=0}^M w_j x_n^{(i+j)} - t_n x_n^i)
\end{aligned}
\]</span></p>
<p>where in <span class="math inline">\((\text{i})\)</span> we use the definition of <span class="math inline">\(y(x_n, \mathbf{w})\)</span>, in <span class="math inline">\((\text{ii})\)</span> we distribute <span class="math inline">\(x_n^i\)</span> into the parentheses, and in <span class="math inline">\((\text{iii})\)</span> we use the exponent rule. Setting the derivative to <span class="math inline">\(0\)</span> and rearranging,</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{n=1}^N (\sum_{j=0}^M w_j x_n^{(i+j)} - t_n x_n^i) &amp; = 0 \\
\sum_{n=1}^N \sum_{j=0}^M w_j x_n^{(i+j)} &amp; = \sum_{n=1}^N t_n x_n^i \\
\sum_{j=0}^M A_{ij}w_j &amp;= T_i
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</section>
<section id="code" class="level4">
<h4 class="anchored" data-anchor-id="code"><strong>1.2 Code</strong></h4>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_A(xs: np.array, M: <span class="bu">int</span>) <span class="op">-&gt;</span> np.array:</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Create the matrix A where A_ij = sum_n=1^N [x_n^(i+j)].</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> np.zeros((M, M))</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For each cell</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(M):</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(M):</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>            A[i][j] <span class="op">=</span> np.<span class="bu">sum</span>(xs<span class="op">**</span>(i<span class="op">+</span>j))</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> A</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_T(xs: np.array, ts: np.array, M: <span class="bu">int</span>) <span class="op">-&gt;</span> np.array:</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co">    Create the vector T where T_i = sum_n=1^N (x_n^i) t_n.</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> np.zeros((M,))</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For each row </span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(M):</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        T[i] <span class="op">=</span> np.<span class="bu">sum</span>((xs <span class="op">**</span> i) <span class="op">*</span> ts)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> T</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_w(xs: np.array, ts: np.array, M: <span class="bu">int</span>) <span class="op">-&gt;</span> np.array:</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co">    Creates A and T using `create_A` and `create_T` and then solves </span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="co">    the linear system of equations to get w.</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> create_A(xs<span class="op">=</span>xs, M<span class="op">=</span>M)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> create_T(xs<span class="op">=</span>xs, ts<span class="op">=</span>ts, M<span class="op">=</span>M)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.linalg.solve(a<span class="op">=</span>A, b<span class="op">=</span>T)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(w: np.array, x: np.array, M) <span class="op">-&gt;</span> np.array:</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="co">    Feature expand the input x and then run the linear</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="co">    transformation involving w,x to get predictions for target t.</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get [x**1, x**2, x**3 ... x**M] for each x</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> x.shape[<span class="dv">0</span>]</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    powers <span class="op">=</span> np.arange(<span class="dv">0</span>, M )</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    powers_expanded <span class="op">=</span> np.tile(powers, (N,)).reshape(N, M)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    xs_expanded <span class="op">=</span> x.repeat(M).reshape(N, M)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>    xs_powered <span class="op">=</span> np.power(xs_expanded, powers_expanded)</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply w</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> w <span class="op">@</span> xs_powered.T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./img/code_signal_and_data.png" class="img-fluid figure-img" width="500"></p>
<figcaption class="figure-caption">Signal (green) and training data (black).</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./img/code_results_for_various_M.png" class="img-fluid figure-img" width="500"></p>
<figcaption class="figure-caption">Signal (green), training data (black), and fitted curves (blue) for various settings of M – the order of the polynomial.</figcaption>
</figure>
</div>
</section>
</section>
<section id="solving-for-the-parameters-with-a-penalty-term" class="level2">
<h2 class="anchored" data-anchor-id="solving-for-the-parameters-with-a-penalty-term">2 Solving for the parameters with a penalty term</h2>
<section id="analytical-setup-1" class="level4">
<h4 class="anchored" data-anchor-id="analytical-setup-1"><strong>2.1 Analytical Setup</strong></h4>
<p>We have the error function <span class="math inline">\(\overset{\sim}{E} (\mathbf{w}) = \frac{1}{2} \sum_{n=1}^N \{y(x_n, \mathbf{w}) \}^2 + \frac{\lambda}{2} \lVert \mathbf{w} \rVert^2\)</span>, where <span class="math inline">\(\lVert \mathbf{w} \rVert^2 = \mathbf{w}^\intercal \mathbf{w} = w_0^2 + w_1^2 + \dots + w_M^2\)</span> and the parameter <span class="math inline">\(\lambda\)</span> controls the strength of regularization. We’d like to find the optimal setting for <span class="math inline">\(\mathbf{w}\)</span> in the sense that it minimizes <span class="math inline">\(\overset{\sim}{E} (\mathbf{w})\)</span>. We will see that we can cast this minimization problem as solving a system of linear equations. We will then solve that system of linear equations with code to attain the optimal <span class="math inline">\(\mathbf{w}^{*}\)</span>.</p>
<p><em>Claim</em>: The <span class="math inline">\(w_i\)</span> in <span class="math inline">\(\mathbf{w} = (w_1, w_2, ..., w_M)\)</span> that minimize the error function <span class="math inline">\(\overset{\sim}{E} (\mathbf{w})\)</span> are given by the solution to the following set of linear equations,</p>
<p><span class="math display">\[
\sum_{j=0}^M A_{ij}w_j + \lambda w_i = T_i \;\; \text{ where } \;\; A_{ij} = \sum_{n=1}^N(x_n)^{(i+j)}, \; T_i = \sum_{n=1}^N (x_n)^i t_n
\]</span></p>
<p><em>Proof</em>: We will take the derivative of <span class="math inline">\(\overset{\sim}{E} (\mathbf{w})\)</span> with respect to <span class="math inline">\(\mathbf{w}\)</span>, set it to zero, and then rearrange terms to prove the claim above.</p>
<p>By the chain rule,</p>
<p><span class="math display">\[
\frac{\partial \overset{\sim}{E}(\mathbf{w})}{\partial w_i} = \frac{\partial E(\mathbf{w})}{\partial y(x_n, \mathbf{w})} \frac{\partial y(x_n, \mathbf{w})}{\partial w_i} + \frac{\lambda}{2} \frac{\partial \mathbf{w}^\intercal \mathbf{w}}{\partial w_i} \tag{2}
\]</span></p>
<p>Solving the two terms on the right hand side yields</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\frac{\partial \overset{\sim}{E}(\mathbf{w})}{\partial y(x_n, \mathbf{w})} = \sum_{n=1}^N \{y(x_n, \mathbf{w}) - t_n \} \\
&amp;\frac{\partial y(x_n, \mathbf{w})}{\partial w_i} = \frac{\partial}{\partial w_i} (w_0 + w_1x_1 + \dots w_i x_n^i \dots + w_m x_n^M) = x_n^i \\
&amp;\frac{\partial \mathbf{w}^\intercal \mathbf{w}}{\partial w_i} = \frac{\partial}{\partial w_i} (w_0^2 + w_1^2 + \dots w_i^2 + \dots w_M^2) = 2 w_i
\end{aligned}
\]</span></p>
<p>Substituting back into <span class="math inline">\((2)\)</span> yields</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial \overset{\sim}{E}(\mathbf{w})}{\partial w_i} &amp; = \sum_{n=1}^N \{y(x_n, \mathbf{w}) - t_n \} x_n^i + \frac{\lambda}{2} 2 w_i \\
&amp; \overset{(i)}{=} \sum_{n=1}^N (\sum_{j=0}^M w_j x_n^{j} - t_n)x_n^i + \lambda w_i  \\
&amp; \overset{(ii)}{=} \sum_{n=1}^N (\sum_{j=0}^M w_j x_n^{i}x_n^j - t_n x_n^i) + \lambda w_i  \\
&amp; \overset{(iii)}{=} \sum_{n=1}^N (\sum_{j=0}^M w_j x_n^{(i+j)} - t_n x_n^i) + \lambda w_i
\end{aligned}
\]</span></p>
<p>where in <span class="math inline">\((\text{i})\)</span> we use the definition of <span class="math inline">\(y(x_n, \mathbf{w})\)</span> and <span class="math inline">\(\frac{\lambda}{2} \cdot 2 = \lambda\)</span>, in <span class="math inline">\((\text{ii})\)</span> we distribute <span class="math inline">\(x_n^i\)</span> into the parentheses, and in <span class="math inline">\((\text{iii})\)</span> we use the exponent rule. Setting the derivative to <span class="math inline">\(0\)</span> and rearranging,</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{n=1}^N (\sum_{j=0}^M w_j x_n^{(i+j)} - t_n x_n^i) + \lambda w_i &amp; = 0 \\
\sum_{n=1}^N \sum_{j=0}^M w_j x_n^{(i+j)} + \lambda w_i &amp; = \sum_{n=1}^N t_n x_n^i \\
\sum_{j=0}^M A_{ij}w_j + \lambda w_i &amp;= T_i
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</section>
<section id="code-1" class="level4">
<h4 class="anchored" data-anchor-id="code-1"><strong>2.2 Code</strong></h4>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ===== Reproducibility ====== #</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Create generator for reproducible resutls</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">123</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>generator <span class="op">=</span> np.random.default_rng(seed)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ===== Data Generation ======= #</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># N = num datapoints; M = order of polynomial</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create signal and noisy signal</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>signal_fn <span class="op">=</span> <span class="kw">lambda</span> x: np.sin(x) </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>signal_noisy_fn <span class="op">=</span> <span class="kw">lambda</span> xs: signal_fn(xs) <span class="op">+</span> generator.normal(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="fl">0.5</span>, size<span class="op">=</span>(N,),)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create training data</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> np.linspace(start<span class="op">=</span><span class="dv">0</span>, stop<span class="op">=</span><span class="dv">5</span>, num<span class="op">=</span>N)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>ts <span class="op">=</span> signal_noisy_fn(xs)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create "signal" </span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>x_axis <span class="op">=</span> np.linspace(start<span class="op">=</span><span class="dv">0</span>, stop<span class="op">=</span><span class="dv">5</span>, num<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>signal <span class="op">=</span> signal_fn(x_axis)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co"># ===== Plot Data ====== #</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Create figure</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>figure1 <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Signal</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>line <span class="op">=</span> np.linspace(start<span class="op">=</span><span class="dv">0</span>, stop<span class="op">=</span><span class="dv">5</span>, num<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>plt.plot(x_axis, signal, c<span class="op">=</span><span class="st">"green"</span>)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot training data</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>plt.scatter(xs, ts, c<span class="op">=</span><span class="st">"black"</span>)</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a><span class="co"># ======= Functions to get W and Predict ====== #</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_A(xs: np.array, M: <span class="bu">int</span>) <span class="op">-&gt;</span> np.array:</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="co">    Create the matrix A where A_ij = sum_n=1^N [x_n^(i+j)].</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> np.zeros((M, M))</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For each cell</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(M):</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(M):</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>            A[i][j] <span class="op">=</span> np.<span class="bu">sum</span>(xs<span class="op">**</span>(i<span class="op">+</span>j))</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> A</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_T(xs: np.array, ts: np.array, M: <span class="bu">int</span>) <span class="op">-&gt;</span> np.array:</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a><span class="co">    Create the vector T where T_i = sum_n=1^N (x_n^i) t_n.</span></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> np.zeros((M,))</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For each row </span></span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(M):</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>        T[i] <span class="op">=</span> np.<span class="bu">sum</span>((xs <span class="op">**</span> i) <span class="op">*</span> ts)</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> T</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_lambdaI(size: <span class="bu">int</span>, ln_lambda: <span class="bu">float</span>) <span class="op">-&gt;</span> np.array:</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a><span class="co">    Create an identity matrix with lambda as the diagonal elements.</span></span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>    lambda_ <span class="op">=</span> np.exp(ln_lambda)</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>    identity <span class="op">=</span> np.eye(N<span class="op">=</span>size)</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> lambda_ <span class="op">*</span> identity</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_w(xs: np.array, ts: np.array, M: <span class="bu">int</span>, ln_lambda: <span class="bu">float</span>) <span class="op">-&gt;</span> np.array:</span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a><span class="co">    Creates A and T using `create_A` and `create_T` and then solves </span></span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a><span class="co">    the linear system of equations to get w.</span></span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> create_A(xs<span class="op">=</span>xs, M<span class="op">=</span>M)</span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>    lambdaI <span class="op">=</span> create_lambdaI(size<span class="op">=</span>M, ln_lambda<span class="op">=</span>ln_lambda)</span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a>    A_plus_lambdaI <span class="op">=</span> A <span class="op">+</span> lambdaI</span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> create_T(xs<span class="op">=</span>xs, ts<span class="op">=</span>ts, M<span class="op">=</span>M)</span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.linalg.solve(a<span class="op">=</span>A_plus_lambdaI, b<span class="op">=</span>T)</span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(w: np.array, x: np.array, M) <span class="op">-&gt;</span> np.array:</span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a><span class="co">    Feature expand the input x and then run the linear</span></span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a><span class="co">    transformation involving w,x to get predictions for target t.</span></span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get [x**1, x**2, x**3 ... x**M] for each x</span></span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> x.shape[<span class="dv">0</span>]</span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a>    powers <span class="op">=</span> np.arange(<span class="dv">0</span>, M )</span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a>    powers_expanded <span class="op">=</span> np.tile(powers, (N,)).reshape(N, M)</span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a>    xs_expanded <span class="op">=</span> x.repeat(M).reshape(N, M)</span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a>    xs_powered <span class="op">=</span> np.power(xs_expanded, powers_expanded)</span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply w</span></span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> w <span class="op">@</span> xs_powered.T</span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a><span class="co"># ======== Find W, Predict, and Plot for various M ======= #</span></span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a>figure <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a>cols, rows <span class="op">=</span> <span class="dv">2</span>, <span class="dv">4</span></span>
<span id="cb2-89"><a href="#cb2-89" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, cols <span class="op">*</span> rows <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb2-90"><a href="#cb2-90" aria-hidden="true" tabindex="-1"></a>    M <span class="op">=</span> i <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb2-91"><a href="#cb2-91" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> get_w(</span>
<span id="cb2-92"><a href="#cb2-92" aria-hidden="true" tabindex="-1"></a>        xs<span class="op">=</span>xs,</span>
<span id="cb2-93"><a href="#cb2-93" aria-hidden="true" tabindex="-1"></a>        ts<span class="op">=</span>ts,</span>
<span id="cb2-94"><a href="#cb2-94" aria-hidden="true" tabindex="-1"></a>        M<span class="op">=</span>M,</span>
<span id="cb2-95"><a href="#cb2-95" aria-hidden="true" tabindex="-1"></a>        ln_lambda<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb2-96"><a href="#cb2-96" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb2-97"><a href="#cb2-97" aria-hidden="true" tabindex="-1"></a>    t_hats <span class="op">=</span> predict(w, line, M)</span>
<span id="cb2-98"><a href="#cb2-98" aria-hidden="true" tabindex="-1"></a>    figure.add_subplot(rows, cols, i)</span>
<span id="cb2-99"><a href="#cb2-99" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">"off"</span>)</span>
<span id="cb2-100"><a href="#cb2-100" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"M = </span><span class="sc">{</span>M<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-101"><a href="#cb2-101" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot signal</span></span>
<span id="cb2-102"><a href="#cb2-102" aria-hidden="true" tabindex="-1"></a>    plt.plot(line, signal_fn(line), label<span class="op">=</span><span class="st">"Signal"</span>, c<span class="op">=</span><span class="st">"green"</span>)</span>
<span id="cb2-103"><a href="#cb2-103" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot data</span></span>
<span id="cb2-104"><a href="#cb2-104" aria-hidden="true" tabindex="-1"></a>    plt.scatter(xs, ts, s <span class="op">=</span> <span class="dv">3</span>, label<span class="op">=</span><span class="st">"Data"</span>, c<span class="op">=</span><span class="st">"black"</span>)</span>
<span id="cb2-105"><a href="#cb2-105" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot predictions</span></span>
<span id="cb2-106"><a href="#cb2-106" aria-hidden="true" tabindex="-1"></a>    plt.plot(line, t_hats, label<span class="op">=</span><span class="st">"Predicted Signal"</span>)</span>
<span id="cb2-107"><a href="#cb2-107" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./img/code_signal_and_data.png" class="img-fluid figure-img" width="500"></p>
<figcaption class="figure-caption">Signal (green) and training data (black).</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./img/code_results_for_various_M_reg.png" class="img-fluid figure-img" width="500"></p>
<figcaption class="figure-caption">Signal (green), training data (black), and fitted curves (blue) for various settings of M – the order of the polynomial, but with with regularization governed by <span class="math inline">\(\text{ln } \lambda = 0\)</span>.</figcaption>
</figure>
</div>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>